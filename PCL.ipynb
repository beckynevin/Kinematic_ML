{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PCL.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPfdF9j4/XJvDxvDciRDPLP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/beckynevin/Kinematic_ML/blob/master/PCL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYzxTF0t-oJa"
      },
      "source": [
        "# Apparently you can clone repos into collab:"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-ouq0DH-dD-",
        "outputId": "5555b475-e301-442e-d3dd-f655a6905e8a"
      },
      "source": [
        "!git clone https://github.com/salesforce/PCL.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'PCL'...\n",
            "remote: Enumerating objects: 141, done.\u001b[K\n",
            "remote: Counting objects: 100% (141/141), done.\u001b[K\n",
            "remote: Compressing objects: 100% (94/94), done.\u001b[K\n",
            "remote: Total 141 (delta 46), reused 134 (delta 42), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (141/141), 191.83 KiB | 1.00 MiB/s, done.\n",
            "Resolving deltas: 100% (46/46), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mD3iQGi1-w-B",
        "outputId": "f4fabba5-b6bd-480b-9c9a-3f4bffa111df"
      },
      "source": [
        "# This is required for the above to work:\n",
        "!pip install faiss-gpu\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting faiss-gpu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/e2/5f90aad74c1bb64279020fbe6d6ca23b6d1ba1fdcce81329f441ee819d59/faiss_gpu-1.7.0-cp36-cp36m-manylinux2014_x86_64.whl (89.4MB)\n",
            "\u001b[K     |████████████████████████████████| 89.4MB 36kB/s \n",
            "\u001b[?25hInstalling collected packages: faiss-gpu\n",
            "Successfully installed faiss-gpu-1.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSCkK20tRAxI"
      },
      "source": [
        "Try to get useful information with (this is wrong but I'd like to be able to do this eventually):\n",
        "parser(PCL/main_pcl.py)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qKzmy4Yv0KW",
        "outputId": "0ffda9e7-c1b7-4326-f207-7631acbdfb98"
      },
      "source": [
        "#!rm -r pngs/\n",
        "#!rm -r _MACOSX/\n",
        "#!rm -r Galaxies/train/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'pngs/': No such file or directory\n",
            "rm: cannot remove '_MACOSX/': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDC6_e08vdxS",
        "outputId": "e449ccf2-e186-4768-b4a4-9925c13f8b50"
      },
      "source": [
        "\n",
        "!unzip train.zip\n",
        "!unzip test.zip\n",
        "# default input is folders for each galaxy "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  train.zip\n",
            "replace train/8464-12701/180.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace train/8262-12705/232.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace train/7990-12702/675.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace train/9185-12704/628.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace train/9863-12703/143.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace train/8452-12702/306.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace train/8262-12702/174.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace train/8554-12703/487.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: Archive:  test.zip\n",
            "replace test/8323-12705/228.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cr20FAvW182d",
        "outputId": "b3114240-6fbd-4cb0-f6f3-3e7d8e16cad0"
      },
      "source": [
        "!python PCL/main_pcl.py -a resnet18 --lr 0.03 --workers 10\\\n",
        "  --batch-size 128 --temperature 0.2 \\\n",
        "  --mlp --aug-plus --cos  --dist-url 'tcp://localhost:10001' \\\n",
        "  --multiprocessing-distributed --world-size 1 \\\n",
        "  --rank 0 --num-cluster 5 --exp-dir PCL/experiment_PCL/ \\\n",
        "   .\n",
        "\n",
        "# batch-size = mini-batch size (total batch size of all GPUs on the current node)\n",
        "# multiprocessing-distributed = use multiprocessing training to launch N processes per node, which has\n",
        "# N GPUs\n",
        "# num-cluster = number of clusters (must specify or it will default to a million)\n",
        "\n",
        "# Getting an error about amount of memory avail to CUDA, apparently you need to \n",
        "# reduce the mini batch size: https://github.com/pytorch/pytorch/issues/16417"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Use GPU: 0 for training\n",
            "=> creating model 'resnet18'\n",
            "MoCo(\n",
            "  (encoder_q): ResNet(\n",
            "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (layer1): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "    (fc): Sequential(\n",
            "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Linear(in_features=512, out_features=128, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (encoder_k): ResNet(\n",
            "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (layer1): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "    (fc): Sequential(\n",
            "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Linear(in_features=512, out_features=128, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Epoch: [0][0/5]\tTime 15.084 (15.084)\tData 13.185 (13.185)\tLoss 5.1976e+00 (5.1976e+00)\tAcc@Inst 100.00 (100.00)\tAcc@Proto   0.00 (  0.00)\n",
            "Epoch: [1][0/5]\tTime 13.484 (13.484)\tData 13.205 (13.205)\tLoss 6.6537e+00 (6.6537e+00)\tAcc@Inst   0.00 (  0.00)\tAcc@Proto   0.00 (  0.00)\n",
            "Epoch: [2][0/5]\tTime 13.262 (13.262)\tData 12.983 (12.983)\tLoss 7.2368e+00 (7.2368e+00)\tAcc@Inst   0.00 (  0.00)\tAcc@Proto   0.00 (  0.00)\n",
            "Epoch: [3][0/5]\tTime 13.251 (13.251)\tData 12.958 (12.958)\tLoss 7.6056e+00 (7.6056e+00)\tAcc@Inst   0.00 (  0.00)\tAcc@Proto   0.00 (  0.00)\n",
            "Epoch: [4][0/5]\tTime 13.445 (13.445)\tData 13.175 (13.175)\tLoss 7.8706e+00 (7.8706e+00)\tAcc@Inst   0.00 (  0.00)\tAcc@Proto   0.00 (  0.00)\n",
            "Epoch: [5][0/5]\tTime 13.280 (13.280)\tData 12.979 (12.979)\tLoss 8.0689e+00 (8.0689e+00)\tAcc@Inst   0.00 (  0.00)\tAcc@Proto   0.00 (  0.00)\n",
            "Epoch: [6][0/5]\tTime 13.001 (13.001)\tData 12.721 (12.721)\tLoss 8.2308e+00 (8.2308e+00)\tAcc@Inst   0.00 (  0.00)\tAcc@Proto   0.00 (  0.00)\n",
            "Epoch: [7][0/5]\tTime 13.225 (13.225)\tData 12.934 (12.934)\tLoss 8.3509e+00 (8.3509e+00)\tAcc@Inst   0.78 (  0.78)\tAcc@Proto   0.00 (  0.00)\n",
            "Epoch: [8][0/5]\tTime 12.987 (12.987)\tData 12.683 (12.683)\tLoss 8.4644e+00 (8.4644e+00)\tAcc@Inst   0.78 (  0.78)\tAcc@Proto   0.00 (  0.00)\n",
            "Epoch: [9][0/5]\tTime 13.044 (13.044)\tData 12.748 (12.748)\tLoss 8.5451e+00 (8.5451e+00)\tAcc@Inst   0.00 (  0.00)\tAcc@Proto   0.00 (  0.00)\n",
            "Epoch: [10][0/5]\tTime 12.983 (12.983)\tData 12.667 (12.667)\tLoss 8.6291e+00 (8.6291e+00)\tAcc@Inst   0.00 (  0.00)\tAcc@Proto   0.00 (  0.00)\n",
            "Epoch: [11][0/5]\tTime 12.879 (12.879)\tData 12.562 (12.562)\tLoss 8.7022e+00 (8.7022e+00)\tAcc@Inst   0.00 (  0.00)\tAcc@Proto   0.00 (  0.00)\n",
            "Epoch: [12][0/5]\tTime 13.100 (13.100)\tData 12.790 (12.790)\tLoss 8.7611e+00 (8.7611e+00)\tAcc@Inst   0.00 (  0.00)\tAcc@Proto   0.00 (  0.00)\n",
            "Epoch: [13][0/5]\tTime 12.880 (12.880)\tData 12.556 (12.556)\tLoss 8.8221e+00 (8.8221e+00)\tAcc@Inst   0.78 (  0.78)\tAcc@Proto   0.00 (  0.00)\n",
            "Epoch: [14][0/5]\tTime 13.236 (13.236)\tData 12.933 (12.933)\tLoss 8.8820e+00 (8.8820e+00)\tAcc@Inst   0.00 (  0.00)\tAcc@Proto   0.00 (  0.00)\n",
            "Epoch: [15][0/5]\tTime 13.165 (13.165)\tData 12.881 (12.881)\tLoss 8.9367e+00 (8.9367e+00)\tAcc@Inst   0.00 (  0.00)\tAcc@Proto   0.00 (  0.00)\n",
            "Epoch: [16][0/5]\tTime 13.152 (13.152)\tData 12.862 (12.862)\tLoss 8.9659e+00 (8.9659e+00)\tAcc@Inst   0.00 (  0.00)\tAcc@Proto   0.00 (  0.00)\n",
            "Epoch: [17][0/5]\tTime 12.950 (12.950)\tData 12.632 (12.632)\tLoss 8.9868e+00 (8.9868e+00)\tAcc@Inst   0.00 (  0.00)\tAcc@Proto   0.00 (  0.00)\n",
            "Epoch: [18][0/5]\tTime 13.321 (13.321)\tData 13.025 (13.025)\tLoss 9.0260e+00 (9.0260e+00)\tAcc@Inst   0.78 (  0.78)\tAcc@Proto   0.00 (  0.00)\n",
            "Epoch: [19][0/5]\tTime 13.501 (13.501)\tData 13.210 (13.210)\tLoss 9.0613e+00 (9.0613e+00)\tAcc@Inst   0.00 (  0.00)\tAcc@Proto   0.00 (  0.00)\n",
            "Computing features...\n",
            "100% 2/2 [00:13<00:00,  6.93s/it]\n",
            "performing kmeans clustering\n",
            "Clustering 686 points in 128D to 5 clusters, redo 5 times, 20 iterations\n",
            "  Preprocessing in 0.00 s\n",
            "Outer iteration 0 / 5\n",
            "  Iteration 19 (0.01 s, search 0.00 s): objective=16.6666 imbalance=1.255 nsplit=0       \n",
            "Objective improved: keep new clusters\n",
            "Outer iteration 1 / 5\n",
            "  Iteration 19 (0.01 s, search 0.01 s): objective=16.639 imbalance=1.181 nsplit=0       \n",
            "Objective improved: keep new clusters\n",
            "Outer iteration 2 / 5\n",
            "  Iteration 19 (0.02 s, search 0.01 s): objective=16.6411 imbalance=1.176 nsplit=0       \n",
            "Outer iteration 3 / 5\n",
            "  Iteration 19 (0.02 s, search 0.02 s): objective=16.6202 imbalance=1.162 nsplit=0       \n",
            "Objective improved: keep new clusters\n",
            "Outer iteration 4 / 5\n",
            "  Iteration 19 (0.03 s, search 0.02 s): objective=16.5867 imbalance=1.162 nsplit=0       \n",
            "Objective improved: keep new clusters\n",
            "Traceback (most recent call last):\n",
            "  File \"PCL/main_pcl.py\", line 553, in <module>\n",
            "    main()\n",
            "  File \"PCL/main_pcl.py\", line 140, in main\n",
            "    mp.spawn(main_worker, nprocs=ngpus_per_node, args=(ngpus_per_node, args))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/multiprocessing/spawn.py\", line 199, in spawn\n",
            "    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/multiprocessing/spawn.py\", line 157, in start_processes\n",
            "    while not context.join():\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/multiprocessing/spawn.py\", line 118, in join\n",
            "    raise Exception(msg)\n",
            "Exception: \n",
            "\n",
            "-- Process 0 terminated with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/multiprocessing/spawn.py\", line 19, in _wrap\n",
            "    fn(i, *args)\n",
            "  File \"/content/PCL/main_pcl.py\", line 321, in main_worker\n",
            "    train(train_loader, model, criterion, optimizer, epoch, args, cluster_result)\n",
            "  File \"/content/PCL/main_pcl.py\", line 358, in train\n",
            "    output, target, output_proto, target_proto = model(im_q=images[0], im_k=images[1], cluster_result=cluster_result, index=index)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/parallel/distributed.py\", line 619, in forward\n",
            "    output = self.module(*inputs[0], **kwargs[0])\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/PCL/pcl/builder.py\", line 180, in forward\n",
            "    neg_proto_id = sample(neg_proto_id,self.r) #sample r negative prototypes\n",
            "  File \"/usr/lib/python3.6/random.py\", line 320, in sample\n",
            "    raise ValueError(\"Sample larger than population or is negative\")\n",
            "ValueError: Sample larger than population or is negative\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91ho0Bj33vrh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ni1BRQUMBP0U"
      },
      "source": [
        "# Now you need your data (optional if you want mnist)\n",
        "import keras\n",
        "import numpy as np\n",
        "import torch\n",
        "(train_images, train_labels), (test_images, test_labels) = keras.datasets.mnist.load_data()\n",
        "\n",
        "print(type(train_images), np.shape(train_images))\n",
        "torch.save(train_images, 'PCL/train_images/images')\n",
        "\n",
        "# Okay try instead getting the whole repo for mnist in .png format\n",
        "!rm -r mnist_png/\n",
        "!git clone https://github.com/myleott/mnist_png.git\n",
        "\n",
        "!tar -xf mnist_png/mnist_png.tar.gz\n",
        "\n",
        "!python PCL/main_pcl.py -a resnet50 --lr 0.03 --workers 10\\\n",
        "  --batch-size 128 --temperature 0.2 \\\n",
        "  --mlp --aug-plus --cos --dist-url 'tcp://localhost:10001' \\\n",
        "  --multiprocessing-distributed --world-size 1 \\\n",
        "  --rank 0 --exp-dir PCL/experiment_PCL/ mnist_png/\n",
        "\n",
        "# batch-size = mini-batch size (total batch size of all GPUs on the current node)\n",
        "# multiprocessing-distributed = use multiprocessing training to launch N processes per node, which has\n",
        "# N GPUs\n",
        "# num-cluster = number of clusters\n",
        "\n",
        "# Getting an error about amount of memory avail to CUDA, apparently you need to \n",
        "# reduce the mini batch size: https://github.com/pytorch/pytorch/issues/16417"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "r_MgiIBkgNHN",
        "outputId": "e30a53ee-4c79-4ea0-cd57-8f20bc4c6152"
      },
      "source": [
        "import torch.cuda\n",
        "\n",
        "torch.cuda.is_available()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-76d82217a40e>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    import faiss-gpu\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    }
  ]
}